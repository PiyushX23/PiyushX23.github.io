---
layout: post
title: "R package to compute statistics from the American Community Survey"
description: ""
category: "R"
tags: [ACS, R]
---



The `acsr` package can be used to extract and compute statistics from the America Community Survey in a more systematic way. It was created for the [Applied Population Laboratory](http://www.apl.wisc.edu/) (APT) at the University of Wisconsin-Madison.

<h2 class="section-heading">Installation</h2>

The functions depends on the `acs` and `data.table` packages, so it is necessary to install then before using `acsr`. The `acsr` package is hosted on a github repository and can be installed using `devtools`:


{% highlight r %}
devtools::install_github("sdaza/acsr")
library(acsr)
{% endhighlight %}



Remember to set the ACS API key, in case you haven't, and to check the help documentation and the default values of the `acsr` functions.


{% highlight r %}
api.key.install(key="*")
?sumacs
?acsdata
{% endhighlight %}

The default level is `state`, specifically the state of Wisconsin (`state = "WI"`), the `endyear` is 2014, and the confidence level to compute margins of error (MOEs) is 90%.

<h2 class="section-heading">Levels</h2>

The `acsr` functions can extract all the levels available in the `acs` package. The table below shows the summary and required levels when using the `acsdata` and `sumacs` functions:

| summary number    | levels                                    |
|----------------   |-----------------------------------------  |
| 010               | us                                        |
| 020               | region                                    |
| 030               | division                                  |
| 040               | state                                     |
| 050               | state, county                             |
| 060               | state, county, county.subdivision         |
| 140               | state, county, tract                      |
| 150               | state, county, tract, block.group         |
| 160               | state, place                              |
| 250               | american.indian.area                      |
| 320               | state, msa                                |
| 340               | state, csa                                |
| 350               | necta                                     |
| 400               | urban.area                                |
| 500               | state, congressional.district             |
| 610               | state, state.legislative.district.upper   |
| 620               | state, state.legislative.district.lower   |
| 795               | state, puma                               |
| 860               | zip.code                                  |
| 950               | state, school.district.elementary         |
| 960               | state, school.district.secondary          |
| 970               | state, school.district.unified            |


<h2 class="section-heading">Getting variables and statistics</h2>

We can use the `sumacs` function to extract variable and statistics. We have to specify the corresponding method (e.g., *proportion* or just *variable*), and the name of the statistic or variable to be included in the output.


{% highlight r %}
sumacs(formula = c("(b16004_004 + b16004_026 + b16004_048 / b16004_001)", "b16004_026"),
        varname = c("langspan0913", "myvar"),
        method = c("prop", "variable"),
        level = c("division"))
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight text %}
##    sumlevel geoid division langspan0913_est langspan0913_moe myvar_est myvar_moe
## 1:      030    NA        1           0.0762         0.000347    770306      3490
## 2:      030    NA        2           0.1182         0.000278   3332150      9171
## 3:      030    NA        3           0.0599         0.000196   1819417      7209
## 4:      030    NA        4           0.0411         0.000277    547577      4461
## 5:      030    NA        5           0.1108         0.000246   4526480     11869
## 6:      030    NA        6           0.0320         0.000265    402475      3781
## 7:      030    NA        7           0.2203         0.000469   5318126     13044
## 8:      030    NA        8           0.1582         0.000602   2279303     10746
## 9:      030    NA        9           0.2335         0.000501   7765838     20289
{% endhighlight %}

To download the data can be slow, especially when many levels are being used (e.g., blockgroup). A better approach in those case is to download the data first using the function `acsdata`, and then use them as input.



{% highlight r %}
mydata <- acsdata(formula = c("(b16004_004 + b16004_026 + b16004_048 /  b16004_001)",
        "b16004_026"),
        level = c("division"))
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight r %}
sumacs(formula = c("(b16004_004 + b16004_026 + b16004_048 / b16004_001)", "b16004_026"),
        varname = c("langspan0913", "myvar"),
        method = c("prop", "variable"),
        level = c("division"),
        data = mydata)
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 2"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  50%"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight text %}
##    sumlevel geoid division langspan0913_est langspan0913_moe myvar_est myvar_moe
## 1:      030    NA        1           0.0762         0.000347    770306      3490
## 2:      030    NA        2           0.1182         0.000278   3332150      9171
## 3:      030    NA        3           0.0599         0.000196   1819417      7209
## 4:      030    NA        4           0.0411         0.000277    547577      4461
## 5:      030    NA        5           0.1108         0.000246   4526480     11869
## 6:      030    NA        6           0.0320         0.000265    402475      3781
## 7:      030    NA        7           0.2203         0.000469   5318126     13044
## 8:      030    NA        8           0.1582         0.000602   2279303     10746
## 9:      030    NA        9           0.2335         0.000501   7765838     20289
{% endhighlight %}

<h2 class="section-heading">Standard errors</h2>

When computing statistics there are two ways to define the standard errors:

- Including all standard errors of the variables used to compute a statistic (`one.zero = FALSE`)
- Include all standard errors except those of variables that are equal to zero. Only the maximum standard error of the variables equal to zero is included  (`one.zero = TRUE`)
- The default value is `one.zero = TRUE`

For more details about how standard errors are computed for proportions, ratios and aggregations look at [A Compass for Understanding and Using American Community Survey Data](https://www.census.gov/content/dam/Census/library/publications/2008/acs/ACSGeneralHandbook.pdf).

Below an example when estimating proportions and using `one.zero = FALSE`:


{% highlight r %}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048) / b16004_001",
            varname = "langspan0913",
            method = "prop",
            level = "tract",
            county = 1, tract = 950501,
            endyear = 2013,
            one.zero = FALSE)
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight text %}
##    sumlevel       geoid st_fips cnty_fips tract_fips langspan0913_est langspan0913_moe
## 1:      140 55001950501      55         1     950501           0.0226           0.0252
{% endhighlight %}

$$ SE = \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2 + 5.47 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0252 $$

When `one.zero = TRUE`:


{% highlight r %}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048) / b16004_001",
            varname = "langspan0913",
            method = "prop",
            level = "tract",
            county = 1, tract = 950501,
            endyear = 2013,
            one.zero = TRUE)
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting tract data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight text %}
##    sumlevel       geoid st_fips cnty_fips tract_fips langspan0913_est langspan0913_moe
## 1:      140 55001950501      55         1     950501           0.0226           0.0245
{% endhighlight %}

$$ SE_{\text{ one.zero}} \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2) - ( 0.02 ^ 2  \times 102.13 ^ 2)}{1546} }  \times 1.645 = 0.0245 $$

When the square root value in the standard error formula doesn't exist (e.g., the square root of a negative number), the ratio formula is instead used. The ratio adjustment is done **variable by variable** .

It can  also be that the `one.zero` option makes the square root undefinable. In those cases, the function uses again the **ratio** formula to compute standard errors. There is also a possibility that the standard error estimates using the **ratio** formula are higher than the **proportion** estimates without the `one.zero` option.

<h2 class="section-heading">Output</h2>

The output can be formatted using a wide or long format:


{% highlight r %}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
            varname = "langspan0913",
            method = "prop",
            level = "division",
            format.out = "long")
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}



{% highlight text %}
##    geoid sumlevel division     var_name    est      moe
## 1:    NA      030        1 langspan0913 0.0762 0.000347
## 2:    NA      030        2 langspan0913 0.1182 0.000278
## 3:    NA      030        3 langspan0913 0.0599 0.000196
## 4:    NA      030        4 langspan0913 0.0411 0.000277
## 5:    NA      030        5 langspan0913 0.1108 0.000246
## 6:    NA      030        6 langspan0913 0.0320 0.000265
## 7:    NA      030        7 langspan0913 0.2203 0.000469
## 8:    NA      030        8 langspan0913 0.1582 0.000602
## 9:    NA      030        9 langspan0913 0.2335 0.000501
{% endhighlight %}

And it can also be exported to a csv file:


{% highlight r %}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
            varname = "langspan0913",
            method = "prop",
            level = "division",
            file = "myfile.out")
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 4"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting division data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Data exported to a CSV file! Done!"
{% endhighlight %}

<h2 class="section-heading">A map?</h2>

Let's color a map using poverty by county:


{% highlight r %}
pov <- sumacs(formula = "b17001_002 / b17001_001 * 100",
        varname = c("pov"),
        method = c("prop"),
        level = c("county"),
        state = "*")
{% endhighlight %}



{% highlight text %}
## [1] ". . . . . .  ACS variables : 2"
## [1] ". . . . . .  Levels : 1"
## [1] ". . . . . .  New variables : 1"
## [1] ". . . . . .  Getting county data"
## [1] ". . . . . .  Done!"
## [1] ". . . . . .  Creating variables"
## [1] ". . . . . .  100%"
## [1] ". . . . . .  Formatting output"
## [1] ". . . . . .  Done!"
{% endhighlight %}


{% highlight r %}
library(choroplethr)
library(choroplethrMaps)
pov[, region := as.numeric(geoid)]
setnames(pov, "pov_est", "value")
county_choropleth(pov, num_colors = 5)
{% endhighlight %}

![center](/img/2016-07-06-acsr/unnamed-chunk-12-1.png)

In sum, the `acsr` package:

- Reads formulas directly and extracts any ACS variable
- Provides an automatized and tailored way to obtain indicators and MOEs
- Allows different outputs' formats (wide and long, csv)
- Provides an easy way to adjust MOEs to different confidence levels
- Includes a variable-by-variable ratio adjustment of standard errors
- Includes the zero-option when computing standard errors for proportions, ratios and aggregations



**Last Update: 08/27/2016**

